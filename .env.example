# OpenAI API Configuration
# Your OpenAI API key for accessing GPT models - required if you would like to use GPT models instead of local models
# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-proj-your-openai-api-key-here

# Data Storage Configuration
# Absolute path to the directory where clinical trial data, mappings, and annotations are stored
# Example: /path/to/your/project/data
DATA_LOC=/path/to/data/directory

# Logging Configuration
# Directory where application logs will be written
# Example: /path/to/your/project/logs
LOG_DIR=/path/to/logs/directory

# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Whether to output logs to console in addition to log files
# Set to True for development, False for production
LOG_TO_CONSOLE=True

# Local LLM Configuration (Optional)
# Name/identifier of the local language model for testing or offline use
LOCAL_LLM=your-local-model-name

# Base URL for local LLM server (e.g., LM Studio, Ollama, or custom endpoint)
# Default LM Studio endpoint: http://127.0.0.1:1234/v1
LOCAL_LLM_URL=http://127.0.0.1:1234/v1

# Graph Database Configuration
# Name of the knowledge graph used for storing clinical trial relationships
# This will be used as the graph database/collection name
GRAPH_NAME=clinical_trial_graph_name