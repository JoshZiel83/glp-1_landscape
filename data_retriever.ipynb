{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32ff5598",
   "metadata": {},
   "source": [
    "#Notebook Setup\n",
    "-Import Dependencies\n",
    "-Load Environmental Variables\n",
    "-Setup Loging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4eef7773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from services import clinicaltrials_retriever, logging_config, mesh_mapper\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d6011f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Initialize logger\n",
    "logger = logging_config.get_logger(__name__)\n",
    "\n",
    "#Set data location\n",
    "DATA_STORAGE = os.getenv(\"DATA_LOC\", None)\n",
    "\n",
    "if DATA_STORAGE and Path(DATA_STORAGE).exists():\n",
    "    logger.info(f\"Data will be saved at:{DATA_STORAGE}\")\n",
    "else:\n",
    "    DATA_STORAGE = Path(__file__).resolve()\n",
    "    logger.warning(f\"Warning: Data storage path in environment does not exist or was not set, saving data here: {DATA_STORAGE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83209bbe",
   "metadata": {},
   "source": [
    "#Define Core Clinical Trials Searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e52e66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_queries = {\n",
    "    \"EFPEGLENATIDE\": \"efpeglenatide\",\n",
    "    \"LIRAGLUTIDE\": \"liraglutide\",\n",
    "    \"SURVODUTIDE\": \"survodutide\",\n",
    "    \"DULAGLUTIDE\": \"dulaglutide\",\n",
    "    \"RETATRUTIDE\": \"retatrutide\",\n",
    "    \"COTADUTIDE\": \"cotadutide\",\n",
    "    \"LIXISENATIDE\": \"lixisenatide\",\n",
    "    \"ALBIGLUTIDE\": \"albiglutide\",\n",
    "    \"PEGSEBRENATIDE\": \"pegsembrenatide\",\n",
    "    \"EXENATIDE\": \"exenatide\",\n",
    "    \"PEGAPAMODUTIDE\": \"pegapamodutide\",\n",
    "    \"AVEXITIDE\": \"avexitide\",\n",
    "    \"TIRZEPATIDE\": \"tirzepatide\",\n",
    "    \"DANUGLIPRON\": \"danuglipron\",\n",
    "    \"EFINOPEGDUTIDE\": \"efinopegdutide\",\n",
    "    \"TASPOGLUTIDE\": \"taspoglutide\",\n",
    "    \"SEMAGLUTIDE\": \"semaglutide\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45fae3a",
   "metadata": {},
   "source": [
    "#Retrieve all clinical trials associated with intervention queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26e1f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_queries_results = []\n",
    "for key in drug_queries.keys():\n",
    "    drug_query = drug_queries[key]\n",
    "    logger.info(f\"Processing drug: {key} with query term: {drug_query}\")\n",
    "\n",
    "    # Retrieve clinical trials\n",
    "    results = clinicaltrials_retriever.retrieve_batched_studies(query_intervention=drug_query)\n",
    "    logger.info(f\"Retrieved {results.shape[0]} clinical trials for drug: {key}\")\n",
    "    results['drug_name'] = key\n",
    "    drug_queries_results.append(results)\n",
    "\n",
    "all_trials = pd.concat(drug_queries_results, axis = 0, ignore_index=True)\n",
    "all_trials.to_csv(f\"{DATA_STORAGE}/all_raw_trials.csv\")\n",
    "logger.info(f\"Retrieved a total of {all_trials.shape[0]} and saved to csv:{DATA_STORAGE}/all_raw_trials.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c23c160",
   "metadata": {},
   "source": [
    "#Trial filtering, data cleaning, and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e1df5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deduplicate_trials(df):\n",
    "    \"\"\"Deduplicate trials and combine drug names\"\"\"\n",
    "    \n",
    "    # Pre-allocate list to collect results\n",
    "    deduped_list = []\n",
    "    \n",
    "    # Group by nct_id to handle duplicates\n",
    "    for nct_id, group in df.groupby('nct_id'):\n",
    "        if len(group) > 1:\n",
    "            logger.info(f\"Deduplicating {len(group)} entries for NCT ID: {nct_id}\")\n",
    "        \n",
    "        # Take first row as template and ensure drug_name column can hold lists\n",
    "        template = group.iloc[0].copy()\n",
    "        \n",
    "        # Get all unique drug names for this trial\n",
    "        drug_names = group['drug_name'].dropna().unique().tolist()\n",
    "        \n",
    "        # Convert to Series to allow assignment\n",
    "        template = pd.Series(template)\n",
    "        template['drug_name'] = drug_names\n",
    "        \n",
    "        deduped_list.append(template)\n",
    "    \n",
    "    # Create DataFrame from list (much more efficient)\n",
    "    deduped_results = pd.DataFrame(deduped_list)\n",
    "    \n",
    "    return deduped_results\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"Remove punctuation with null handling\"\"\"\n",
    "    if pd.isna(text) or text is None:\n",
    "        return \"\"\n",
    "    return str(text).translate(str.maketrans('', '', string.punctuation)).upper()\n",
    "\n",
    "def convert_date(text):\n",
    "    \"\"\"\n",
    "    Convert date to standard object\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or text is None:\n",
    "        return None\n",
    "    elif \"-\" in text:\n",
    "        date_info = text.split(\"-\")\n",
    "        if len(date_info) == 2:\n",
    "            year = int(date_info[0])\n",
    "            month = int(date_info[1])\n",
    "            return datetime(year = year, month = month, day = 1)\n",
    "        if len(date_info) == 3:\n",
    "            year = int(date_info[0])\n",
    "            month = int(date_info[1])\n",
    "            day = int(date_info[2])\n",
    "            return datetime(year = year, month = month, day = day)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def calculate_duration(row):\n",
    "    \"\"\"\n",
    "    Precise calculation using total_seconds with robust null handling\n",
    "    \"\"\"\n",
    "    start_date = row['cln_start_date']\n",
    "    completion_date = row['cln_completion_date']\n",
    "    \n",
    "    # Handle various types of missing/empty values\n",
    "    if (pd.isna(start_date) or pd.isna(completion_date) or \n",
    "        start_date is None or completion_date is None or\n",
    "        start_date == '' or completion_date == ''):\n",
    "        return None\n",
    "    \n",
    "    # Calculate duration using total_seconds for precision\n",
    "    duration = completion_date - start_date\n",
    "    seconds_per_year = 365.25 * 24 * 60 * 60\n",
    "    years = duration.total_seconds() / seconds_per_year\n",
    "    return round(years, 1)\n",
    "\n",
    "def generate_mesh_term_map(df):\n",
    "    \"\"\"\n",
    "    Map conditions column to best matching MeSH condition term\n",
    "    \"\"\"\n",
    "    unique_conditions = df.conditions.explode().unique()\n",
    "    term_mappings = {}\n",
    "    for condition in tqdm(unique_conditions, desc=\"Matching conditions to MeSH terms\"):\n",
    "        if pd.notna(condition) and condition:  # Skip null/empty conditions\n",
    "            result = mesh_mapper.search_mesh_term(condition, filter_diseases_only=True)  # Change to True to filter\n",
    "            if result:\n",
    "                mapping = f\"{result[\"mesh_term\"]} (MeSH ID:{result[\"mesh_id\"]})\"\n",
    "                term_mappings[condition] = mapping\n",
    "            # Add delay after each search to respect rate limits\n",
    "            time.sleep(0.35)\n",
    "    # Display results\n",
    "    logger.info(f\"\\nSuccessfully matched {len(term_mappings.keys())} conditions to MeSH terms\")\n",
    "    return term_mappings\n",
    "\n",
    "def add_mesh_mappings(conditions, term_map):\n",
    "    \"\"\"\n",
    "    Apply the MeSH term mapping to the Data\n",
    "    \"\"\"\n",
    "    matched_conditions = []\n",
    "    if conditions is not None and len(conditions)>0:  # Skip null/empty conditions\n",
    "        for condition in conditions:\n",
    "            if term_map.keys() and condition in term_map.keys():\n",
    "                matched_term = term_map[condition]\n",
    "                logger.info(f\"Found a MeSH term mapping for {condition}\")\n",
    "                matched_conditions.append(matched_term)\n",
    "            else:\n",
    "                logger.info(f\"No existing MeSH term mapping for {condition}\")\n",
    "    return list(set(matched_conditions))\n",
    "\n",
    "#Deduplication\n",
    "logger.info(f\"Deduplicating {all_trials.shape[0]} trials\")\n",
    "deduped_trials = deduplicate_trials(all_trials)\n",
    "logger.info(f\"Removed {all_trials.shape[0]-deduped_trials.shape[0]} trials during de-duplication\")\n",
    "\n",
    "#Data Cleaning\n",
    "logger.info(f\"Initiating data clean-up on {deduped_trials.shape[0]} trials.\")\n",
    "cleaned_trials = deduped_trials[\n",
    "    # Check if 'DRUG' is in intervention_types list\n",
    "    (deduped_trials['intervention_types'].apply(\n",
    "        lambda x: isinstance(x, list) and ('DRUG' or 'BIOLOGICAL') in x\n",
    "    )) \n",
    "    & \n",
    "    # Check healthy_volunteers \n",
    "    ((deduped_trials['healthy_volunteers'] == False) | \n",
    "     (deduped_trials['healthy_volunteers'].isnull()))\n",
    "    & \n",
    "    # Check study type\n",
    "    (deduped_trials['study_type'] == 'INTERVENTIONAL')\n",
    "    &\n",
    "    # Check if primary_outcomes is not empty/null\n",
    "    (deduped_trials['primary_outcomes'].notna() & \n",
    "     (deduped_trials['primary_outcomes'].astype(str) != '[]'))\n",
    "    &\n",
    "    # Check if interventions is not empty/null  \n",
    "    (deduped_trials['interventions'].notna() & \n",
    "     (deduped_trials['interventions'].astype(str) != '[]'))\n",
    "].copy()\n",
    "mesh_term_map = generate_mesh_term_map(cleaned_trials)\n",
    "mesh_frame = pd.DataFrame.from_dict(mesh_term_map, orient = 'index')\n",
    "mesh_frame.to_csv(f\"{DATA_STORAGE}/mesh_term_mappings.csv\")\n",
    "\n",
    "\n",
    "cleaned_trials['cleaned_sponsor'] = cleaned_trials['lead_sponsor'].apply(remove_punctuation)\n",
    "cleaned_trials['cln_start_date']= cleaned_trials['start_date'].apply(convert_date)\n",
    "cleaned_trials['cln_completion_date']= cleaned_trials['completion_date'].apply(convert_date)\n",
    "cleaned_trials['duration'] = cleaned_trials.apply(calculate_duration, axis = 1)\n",
    "cleaned_trials[\"matched_conditions\"] = cleaned_trials[\"conditions\"].apply(add_mesh_mappings, term_map=mesh_term_map)\n",
    "cleaned_trials['llm_annotations'] = [[] for _ in range(len(cleaned_trials))]\n",
    "cleaned_trials.shape\n",
    "\n",
    "#Trial saved as CSV for ease of review and as a pkl - the pkl should be used by the annotator notebook\n",
    "cleaned_trials.to_csv(f\"{DATA_STORAGE}/cleaned_trials.csv\")\n",
    "with open(f\"{DATA_STORAGE}/cleaned_trials.pkl\", 'wb') as f:\n",
    "    pickle.dump(cleaned_trials, f)\n",
    "logger.info(f\"Saved {cleaned_trials.shape[0]} trials after data cleaning in {DATA_STORAGE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f9a78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reload the Dataframe from Pickle of Necessary\n",
    "cleaned_trials_loc = \"data/cleaned_trials.pkl\"\n",
    "if Path(cleaned_trials_loc).exists():\n",
    "    with open(cleaned_trials_loc, \"rb\") as f:\n",
    "        cleaned_trials = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glp-1-landscape-nG0L0imC-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
