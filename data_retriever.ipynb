{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "h2vznjv0t7",
   "metadata": {},
   "source": [
    "# Clinical Trials Data Retrieval Pipeline\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook is the **first step** in an educational pipeline demonstrating how Large Language Models (LLMs) can assist biotech and lifesciences professionals with clinical research analysis.\n",
    "\n",
    "## Purpose\n",
    "\n",
    "We'll retrieve, clean, and standardize clinical trial data for GLP-1 receptor agonists and related medications - a drug class that has revolutionized treatment for Type 2 Diabetes and obesity.\n",
    "\n",
    "## Pipeline Stages\n",
    "\n",
    "**Stage 1: Setup and Configuration**\n",
    "- Import required libraries and services\n",
    "- Configure logging and data storage locations\n",
    "\n",
    "**Stage 2: Data Retrieval**\n",
    "- Define target drugs to search for\n",
    "- Query ClinicalTrials.gov API for relevant trials\n",
    "- Save raw results for checkpoint\n",
    "\n",
    "**Stage 3: Data Processing and Enrichment**\n",
    "- Deduplicate trials that appear in multiple searches\n",
    "- Apply quality filters to focus on relevant studies\n",
    "- Map free-text medical conditions to standardized MeSH terms\n",
    "- Clean dates and calculate trial durations\n",
    "- Export processed data for downstream analysis\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "The cleaned data from this notebook feeds into `data_annotator.ipynb`, where we'll use LLMs to extract structured insights from trial descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4eef7773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from services import clinicaltrials_retriever, logging_config, mesh_mapper\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d6011f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Initialize logger\n",
    "logger = logging_config.get_logger(__name__)\n",
    "\n",
    "#Set data location\n",
    "DATA_STORAGE = os.getenv(\"DATA_LOC\", None)\n",
    "\n",
    "if DATA_STORAGE and Path(DATA_STORAGE).exists():\n",
    "    logger.info(f\"Data will be saved at:{DATA_STORAGE}\")\n",
    "else:\n",
    "    DATA_STORAGE = Path(__file__).resolve()\n",
    "    logger.warning(f\"Warning: Data storage path in environment does not exist or was not set, saving data here: {DATA_STORAGE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c30uns17qv",
   "metadata": {},
   "source": [
    "## About GLP-1 Receptor Agonists\n",
    "\n",
    "### Background\n",
    "\n",
    "**GLP-1 (Glucagon-Like Peptide-1)** is a hormone naturally produced in the intestine that regulates blood sugar and appetite. GLP-1 receptor agonists are medications that mimic this hormone's effects.\n",
    "\n",
    "### Drug Categories\n",
    "\n",
    "**Single Agonists** (Target GLP-1 receptor only)\n",
    "Examples:\n",
    "- Liraglutide (Victoza, Saxenda)\n",
    "- Semaglutide (Ozempic, Wegovy, Rybelsus)  \n",
    "- Dulaglutide (Trulicity)\n",
    "- Exenatide (Byetta, Bydureon)\n",
    "- Lixisenatide (Adlyxin)\n",
    "\n",
    "**Dual Agonists** (Target GLP-1 + another receptor)\n",
    "Examples:\n",
    "- Tirzepatide (Mounjaro, Zepbound) - GLP-1/GIP\n",
    "- Survodutide - GLP-1/Glucagon\n",
    "- Cotadutide - GLP-1/Glucagon\n",
    "\n",
    "**Triple Agonists** (Target GLP-1 + GIP + Glucagon)\n",
    "Example:\n",
    "- Retatrutide (in development)\n",
    "\n",
    "### Why This Drug Class Matters\n",
    "\n",
    "Originally developed for Type 2 Diabetes, these drugs have shown remarkable efficacy for:\n",
    "- Weight management (10-20% body weight reduction)\n",
    "- Cardiovascular disease prevention\n",
    "- Non-alcoholic fatty liver disease (NAFLD/NASH)\n",
    "- Potential neuroprotective effects\n",
    "\n",
    "The clinical trial landscape for these drugs is rapidly evolving, making it an excellent case study for computational analysis.\n",
    "\n",
    "### What We'll Retrieve\n",
    "\n",
    "Below we define 17 drugs from this class based on drugs in ChEMBL. We'll search ClinicalTrials.gov for all trials testing these interventions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e52e66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_queries = {\n",
    "    \"EFPEGLENATIDE\": \"efpeglenatide\",\n",
    "    \"LIRAGLUTIDE\": \"liraglutide\",\n",
    "    \"SURVODUTIDE\": \"survodutide\",\n",
    "    \"DULAGLUTIDE\": \"dulaglutide\",\n",
    "    \"RETATRUTIDE\": \"retatrutide\",\n",
    "    \"COTADUTIDE\": \"cotadutide\",\n",
    "    \"LIXISENATIDE\": \"lixisenatide\",\n",
    "    \"ALBIGLUTIDE\": \"albiglutide\",\n",
    "    \"PEGSEBRENATIDE\": \"pegsembrenatide\",\n",
    "    \"EXENATIDE\": \"exenatide\",\n",
    "    \"PEGAPAMODUTIDE\": \"pegapamodutide\",\n",
    "    \"AVEXITIDE\": \"avexitide\",\n",
    "    \"TIRZEPATIDE\": \"tirzepatide\",\n",
    "    \"DANUGLIPRON\": \"danuglipron\",\n",
    "    \"EFINOPEGDUTIDE\": \"efinopegdutide\",\n",
    "    \"TASPOGLUTIDE\": \"taspoglutide\",\n",
    "    \"SEMAGLUTIDE\": \"semaglutide\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "okeruabsie",
   "metadata": {},
   "source": [
    "## Data Retrieval from ClinicalTrials.gov\n",
    "\n",
    "### About ClinicalTrials.gov\n",
    "\n",
    "**ClinicalTrials.gov** is the U.S. government's database of clinical studies conducted worldwide, maintained by the National Library of Medicine (NLM). \n",
    "\n",
    "### What We're Retrieving\n",
    "\n",
    "For each drug in our list, we'll query the API to retrieve:\n",
    "\n",
    "**Trial Metadata:**\n",
    "- NCT ID (unique identifier, e.g., NCT04567890)\n",
    "- Study title and brief description\n",
    "- Trial phase (e.g., Phase 1, 2, 3, or 4)\n",
    "- Study type (interventional vs observational)\n",
    "\n",
    "**Enrollment Information:**\n",
    "- Target enrollment numbers\n",
    "- Eligibility criteria\n",
    "- Inclusion of healthy volunteers\n",
    "\n",
    "**Study Design:**\n",
    "- Conditions being studied\n",
    "- Interventions being tested\n",
    "- Primary and secondary outcomes\n",
    "\n",
    "**Timeline:**\n",
    "- Start date and completion date\n",
    "- Current recruitment status\n",
    "\n",
    "**Sponsor Information:**\n",
    "- Lead sponsor organization\n",
    "- Collaborators\n",
    "\n",
    "### Expected Duplicates\n",
    "\n",
    "**Important:** Some trials test multiple drugs from our list (e.g., head-to-head comparisons of Semaglutide vs Liraglutide). These trials will appear in search results for both drugs. We'll handle this redundancy in the deduplication step below.\n",
    "\n",
    "### Processing Time\n",
    "\n",
    "Retrieving large numbers of trials may take time due to API rate limits and data parsing. You'll be able to see progress if you left LOG_TO_CONSOLE as true in your .env file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26e1f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_queries_results = []\n",
    "for key in drug_queries.keys():\n",
    "    drug_query = drug_queries[key]\n",
    "    logger.info(f\"Processing drug: {key} with query term: {drug_query}\")\n",
    "\n",
    "    # Retrieve clinical trials\n",
    "    results = clinicaltrials_retriever.retrieve_batched_studies(query_intervention=drug_query)\n",
    "    logger.info(f\"Retrieved {results.shape[0]} clinical trials for drug: {key}\")\n",
    "    results['drug_name'] = key\n",
    "    drug_queries_results.append(results)\n",
    "\n",
    "all_trials = pd.concat(drug_queries_results, axis = 0, ignore_index=True)\n",
    "all_trials.to_csv(f\"{DATA_STORAGE}/all_raw_trials.csv\")\n",
    "logger.info(f\"Retrieved a total of {all_trials.shape[0]} and saved to csv:{DATA_STORAGE}/all_raw_trials.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quxwxx00gp",
   "metadata": {},
   "source": [
    "## Data Quality and Standardization\n",
    "\n",
    "Raw clinical trial data from ClinicalTrials.gov requires significant cleaning before meaningful analysis. This section performs several critical transformations:\n",
    "\n",
    "### 1. Deduplication\n",
    "\n",
    "**The Problem:**  \n",
    "Trials testing multiple drugs from our list appear multiple times in our raw results - once for each drug query.\n",
    "\n",
    "**The Solution:**  \n",
    "We identify duplicate trials by their unique **NCT ID** (ClinicalTrials.gov identifier). For each duplicate:\n",
    "- Keep a single record\n",
    "- Combine all associated drug names into a list\n",
    "- Preserve all other trial metadata\n",
    "\n",
    "**Example:**\n",
    "- Raw data: 2 rows for NCT12345678 (one tagged \"SEMAGLUTIDE\", one tagged \"LIRAGLUTIDE\")  \n",
    "- Cleaned data: 1 row for NCT12345678 with `drug_name = [\"SEMAGLUTIDE\", \"LIRAGLUTIDE\"]`\n",
    "\n",
    "This approach maintains complete information while eliminating redundancy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "y6tgcnuamn",
   "metadata": {},
   "source": [
    "### 2. Quality Filtering\n",
    "\n",
    "Not all trials in ClinicalTrials.gov are relevant for our drug efficacy analysis. We apply strict filters to focus on high-quality, patient-focused interventional studies.\n",
    "\n",
    "**Filters Applied:**\n",
    "\n",
    "✅ **Drug/Biological Interventions Only**  \n",
    "- Include: Pharmaceutical drugs and biologics\n",
    "- Exclude: Behavioral interventions, devices, surgical procedures, dietary supplements\n",
    "\n",
    "✅ **Patient Populations (No Healthy Volunteers)**  \n",
    "- Include: Studies enrolling patients with medical conditions\n",
    "- Exclude: Pharmacokinetic studies in healthy volunteers (Phase 1 safety studies)\n",
    "- *Why?* We're interested in therapeutic efficacy, not basic safety/metabolism studies\n",
    "\n",
    "✅ **Interventional Studies Only**  \n",
    "- Include: Randomized controlled trials (RCTs), single-arm trials where interventions are assigned\n",
    "- Exclude: Observational/epidemiological studies\n",
    "- *Why?* Interventional studies provide the strongest evidence for drug efficacy\n",
    "\n",
    "✅ **Well-Defined Endpoints**  \n",
    "- Include: Trials with documented primary outcome measures\n",
    "- Exclude: Trials missing outcome definitions\n",
    "- *Why?* Ensures we can meaningfully analyze what the trial is measuring\n",
    "\n",
    "✅ **Documented Interventions**  \n",
    "- Include: Trials with clear intervention descriptions\n",
    "- Exclude: Trials with missing or empty intervention fields\n",
    "- *Why?* Essential metadata for understanding study design\n",
    "\n",
    "**Expected Impact:**  \n",
    "These filters typically remove 20-30% of raw trials, focusing our analysis on the most clinically relevant studies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "y93ucm6z36",
   "metadata": {},
   "source": [
    "### 3. Medical Terminology Standardization with MeSH\n",
    "\n",
    "#### The Challenge: Inconsistent Medical Terminology\n",
    "\n",
    "Clinical trials describe conditions using varied, non-standardized terminology. For example, these all refer to the same condition:\n",
    "\n",
    "| Free-Text in ClinicalTrials.gov | All Mean... |\n",
    "|--------------------------------|-------------|\n",
    "| \"Type 2 Diabetes Mellitus\" | Same condition |\n",
    "| \"T2DM\" | Same condition |  \n",
    "| \"Diabetes Mellitus, Type 2\" | Same condition |\n",
    "| \"Non-Insulin-Dependent Diabetes\" | Same condition |\n",
    "| \"Adult-Onset Diabetes\" | Same condition |\n",
    "\n",
    "Without standardization, analysis becomes impossible:\n",
    "- Counting trials by condition gives fragmented results\n",
    "- Text-based grouping misses synonyms and abbreviations  \n",
    "- Comparison across datasets requires manual mapping\n",
    "\n",
    "#### The Solution: MeSH (Medical Subject Headings)\n",
    "\n",
    "**MeSH** is the National Library of Medicine's controlled vocabulary for biomedical concepts, used to index all PubMed articles since 1960.\n",
    "\n",
    "**Key Features:**\n",
    "- **Controlled vocabulary**: Single canonical term per concept\n",
    "- **Hierarchical structure**: Terms organized in tree-like classifications (e.g., Diseases → Metabolic Diseases → Diabetes Mellitus)\n",
    "- **Unique identifiers**: Each term has a stable MeSH ID (e.g., D003924)\n",
    "- **Mapping service**: APIs to map free-text to official MeSH terms\n",
    "\n",
    "#### Our MeSH Mapping Process\n",
    "\n",
    "1. **Extract unique conditions** from all filtered trials\n",
    "2. **Query NCBI's E-utilities API** for each condition\n",
    "3. **Filter to disease/disorder terms only** (MeSH tree codes starting with 'C' or 'F')\n",
    "4. **Return the best match**: Standardized MeSH term + unique ID\n",
    "5. **Apply mappings** to create a new `matched_conditions` column\n",
    "\n",
    "#### Example Mapping Result\n",
    "\n",
    "```\n",
    "Input:  \"Type II Diabetes\"\n",
    "Output: \"Diabetes Mellitus, Type 2 (MeSH ID:D003924)\"\n",
    "```\n",
    "\n",
    "#### Why This Matters\n",
    "\n",
    "- **Accurate grouping**: All trials studying diabetes map to the same MeSH term\n",
    "- **Literature integration**: Can link to PubMed articles using same MeSH tags\n",
    "- **Downstream analysis**: LLMs and algorithms can work with consistent terminology\n",
    "- **Reproducibility**: MeSH terms are stable over time (unlike free-text)\n",
    "\n",
    "#### Processing Time\n",
    "\n",
    "This step takes several minutes because:\n",
    "- Each unique condition requires an API call to NCBI  \n",
    "- We respect rate limits (0.35 seconds between requests = ~3 requests/second)\n",
    "- Typical dataset has 100-200 unique condition terms\n",
    "\n",
    "**Progress bar below shows real-time mapping status.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iw854qtjn4",
   "metadata": {},
   "source": [
    "### 4. Additional Data Cleaning and Enrichment\n",
    "\n",
    "Before exporting, we perform several final transformations to make the data more analysis-ready:\n",
    "\n",
    "#### Date Standardization\n",
    "Clinical trial dates come in various formats:\n",
    "- `\"2023\"` (year only)\n",
    "- `\"2023-06\"` (year-month)\n",
    "- `\"2023-06-15\"` (full date)\n",
    "\n",
    "We convert all dates to Python `datetime` objects for consistent processing.\n",
    "\n",
    "#### Trial Duration Calculation  \n",
    "Using standardized dates, we calculate trial duration in years:\n",
    "```\n",
    "duration = (completion_date - start_date) / 365.25\n",
    "```\n",
    "\n",
    "This metric helps identify:\n",
    "- Short-term efficacy studies (0.5-2 years)\n",
    "- Long-term safety studies (3+ years)\n",
    "- Stalled or abandoned trials (unrealistic durations)\n",
    "\n",
    "#### Sponsor Name Cleaning\n",
    "Pharmaceutical company names appear with inconsistent formatting:\n",
    "- \"Novo Nordisk A/S\"\n",
    "- \"NOVO NORDISK\"  \n",
    "- \"Novo-Nordisk\"\n",
    "\n",
    "We remove punctuation and standardize capitalization for better grouping in analysis.\n",
    "\n",
    "#### New Column: `llm_annotations`\n",
    "We initialize an empty list for each trial. This will be populated in the next notebook (`data_annotator.ipynb`) where we'll use LLMs to extract structured insights from trial descriptions.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Export Formats\n",
    "\n",
    "We save the cleaned dataset in **two formats**, each optimized for different use cases:\n",
    "\n",
    "#### CSV Format (`cleaned_trials.csv`)\n",
    "\n",
    "**Pros:**\n",
    "- Human-readable in text editors\n",
    "- Opens in Excel, Google Sheets, or any spreadsheet software\n",
    "- Easy to share with non-technical stakeholders\n",
    "- Version control friendly (can see line-by-line diffs)\n",
    "\n",
    "**Cons:**\n",
    "- Lists and complex data types get flattened to strings\n",
    "- Datetime objects converted to text\n",
    "- Larger file size\n",
    "- Slower to load for large datasets\n",
    "\n",
    "**Best for:** Quick review, sharing, manual inspection\n",
    "\n",
    "---\n",
    "\n",
    "#### Pickle Format (`cleaned_trials.pkl`)\n",
    "\n",
    "**Pros:**\n",
    "- Preserves Python data types exactly:\n",
    "  - Lists stay as lists (e.g., `drug_name`, `conditions`)\n",
    "  - Datetime objects stay as datetime objects\n",
    "  - Complex nested structures maintained\n",
    "- Faster to load and save\n",
    "- Smaller file size (binary compression)\n",
    "\n",
    "**Cons:**\n",
    "- Not human-readable (binary format)\n",
    "- Python-specific (can't open in Excel)\n",
    "- Version control shows binary diffs (not useful for code review)\n",
    "\n",
    "**Best for:** Downstream Python analysis\n",
    "\n",
    "---\n",
    "\n",
    "### ⚠️ Important for Next Steps\n",
    "\n",
    "**Use the pickle file (`cleaned_trials.pkl`) in the next notebook (`data_annotator.ipynb`).**\n",
    "\n",
    "Why? The pickle preserves list structures and datetime objects that are essential for LLM annotation workflows.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary of New/Cleaned Columns\n",
    "\n",
    "| Column | Description | Example |\n",
    "|--------|-------------|---------|\n",
    "| `drug_name` | List of GLP-1 drugs tested | `[\"SEMAGLUTIDE\", \"LIRAGLUTIDE\"]` |\n",
    "| `cleaned_sponsor` | Standardized sponsor name | `\"NOVO NORDISK\"` |\n",
    "| `cln_start_date` | Parsed start date | `datetime(2023, 6, 1)` |\n",
    "| `cln_completion_date` | Parsed completion date | `datetime(2025, 12, 31)` |\n",
    "| `duration` | Trial length in years | `2.6` |\n",
    "| `matched_conditions` | MeSH-standardized conditions | `[\"Diabetes Mellitus, Type 2 (MeSH ID:D003924)\"]` |\n",
    "| `llm_annotations` | Placeholder to trace data added by LLMs| `[]` (empty, filled in next notebook) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e1df5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deduplicate_trials(df):\n",
    "    \"\"\"Deduplicate trials and combine drug names\"\"\"\n",
    "    \n",
    "    # Pre-allocate list to collect results\n",
    "    deduped_list = []\n",
    "    \n",
    "    # Group by nct_id to handle duplicates\n",
    "    for nct_id, group in df.groupby('nct_id'):\n",
    "        if len(group) > 1:\n",
    "            logger.info(f\"Deduplicating {len(group)} entries for NCT ID: {nct_id}\")\n",
    "        \n",
    "        # Take first row as template and ensure drug_name column can hold lists\n",
    "        template = group.iloc[0].copy()\n",
    "        \n",
    "        # Get all unique drug names for this trial\n",
    "        drug_names = group['drug_name'].dropna().unique().tolist()\n",
    "        \n",
    "        # Convert to Series to allow assignment\n",
    "        template = pd.Series(template)\n",
    "        template['drug_name'] = drug_names\n",
    "        \n",
    "        deduped_list.append(template)\n",
    "    \n",
    "    # Create DataFrame from list (much more efficient)\n",
    "    deduped_results = pd.DataFrame(deduped_list)\n",
    "    \n",
    "    return deduped_results\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"Remove punctuation with null handling\"\"\"\n",
    "    if pd.isna(text) or text is None:\n",
    "        return \"\"\n",
    "    return str(text).translate(str.maketrans('', '', string.punctuation)).upper()\n",
    "\n",
    "def convert_date(text):\n",
    "    \"\"\"\n",
    "    Convert date to standard object\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or text is None:\n",
    "        return None\n",
    "    elif \"-\" in text:\n",
    "        date_info = text.split(\"-\")\n",
    "        if len(date_info) == 2:\n",
    "            year = int(date_info[0])\n",
    "            month = int(date_info[1])\n",
    "            return datetime(year = year, month = month, day = 1)\n",
    "        if len(date_info) == 3:\n",
    "            year = int(date_info[0])\n",
    "            month = int(date_info[1])\n",
    "            day = int(date_info[2])\n",
    "            return datetime(year = year, month = month, day = day)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def calculate_duration(row):\n",
    "    \"\"\"\n",
    "    Precise calculation using total_seconds with robust null handling\n",
    "    \"\"\"\n",
    "    start_date = row['cln_start_date']\n",
    "    completion_date = row['cln_completion_date']\n",
    "    \n",
    "    # Handle various types of missing/empty values\n",
    "    if (pd.isna(start_date) or pd.isna(completion_date) or \n",
    "        start_date is None or completion_date is None or\n",
    "        start_date == '' or completion_date == ''):\n",
    "        return None\n",
    "    \n",
    "    # Calculate duration using total_seconds for precision\n",
    "    duration = completion_date - start_date\n",
    "    seconds_per_year = 365.25 * 24 * 60 * 60\n",
    "    years = duration.total_seconds() / seconds_per_year\n",
    "    return round(years, 1)\n",
    "\n",
    "def generate_mesh_term_map(df):\n",
    "    \"\"\"\n",
    "    Map conditions column to best matching MeSH condition term\n",
    "    \"\"\"\n",
    "    unique_conditions = df.conditions.explode().unique()\n",
    "    term_mappings = {}\n",
    "    for condition in tqdm(unique_conditions, desc=\"Matching conditions to MeSH terms\"):\n",
    "        if pd.notna(condition) and condition:  # Skip null/empty conditions\n",
    "            result = mesh_mapper.search_mesh_term(condition, filter_diseases_only=True)  # Change to True to filter\n",
    "            if result:\n",
    "                mapping = f\"{result[\"mesh_term\"]} (MeSH ID:{result[\"mesh_id\"]})\"\n",
    "                term_mappings[condition] = mapping\n",
    "            # Add delay after each search to respect rate limits\n",
    "            time.sleep(0.35)\n",
    "    # Display results\n",
    "    logger.info(f\"\\nSuccessfully matched {len(term_mappings.keys())} conditions to MeSH terms\")\n",
    "    return term_mappings\n",
    "\n",
    "def add_mesh_mappings(conditions, term_map):\n",
    "    \"\"\"\n",
    "    Apply the MeSH term mapping to the Data\n",
    "    \"\"\"\n",
    "    matched_conditions = []\n",
    "    if conditions is not None and len(conditions)>0:  # Skip null/empty conditions\n",
    "        for condition in conditions:\n",
    "            if term_map.keys() and condition in term_map.keys():\n",
    "                matched_term = term_map[condition]\n",
    "                logger.info(f\"Found a MeSH term mapping for {condition}\")\n",
    "                matched_conditions.append(matched_term)\n",
    "            else:\n",
    "                logger.info(f\"No existing MeSH term mapping for {condition}\")\n",
    "    return list(set(matched_conditions))\n",
    "\n",
    "#Deduplication\n",
    "logger.info(f\"Deduplicating {all_trials.shape[0]} trials\")\n",
    "deduped_trials = deduplicate_trials(all_trials)\n",
    "logger.info(f\"Removed {all_trials.shape[0]-deduped_trials.shape[0]} trials during de-duplication\")\n",
    "\n",
    "#Data Cleaning\n",
    "logger.info(f\"Initiating data clean-up on {deduped_trials.shape[0]} trials.\")\n",
    "cleaned_trials = deduped_trials[\n",
    "    # Check if 'DRUG' is in intervention_types list\n",
    "    (deduped_trials['intervention_types'].apply(\n",
    "        lambda x: isinstance(x, list) and ('DRUG' or 'BIOLOGICAL') in x\n",
    "    )) \n",
    "    & \n",
    "    # Check healthy_volunteers \n",
    "    ((deduped_trials['healthy_volunteers'] == False) | \n",
    "     (deduped_trials['healthy_volunteers'].isnull()))\n",
    "    & \n",
    "    # Check study type\n",
    "    (deduped_trials['study_type'] == 'INTERVENTIONAL')\n",
    "    &\n",
    "    # Check if primary_outcomes is not empty/null\n",
    "    (deduped_trials['primary_outcomes'].notna() & \n",
    "     (deduped_trials['primary_outcomes'].astype(str) != '[]'))\n",
    "    &\n",
    "    # Check if interventions is not empty/null  \n",
    "    (deduped_trials['interventions'].notna() & \n",
    "     (deduped_trials['interventions'].astype(str) != '[]'))\n",
    "].copy()\n",
    "mesh_term_map = generate_mesh_term_map(cleaned_trials)\n",
    "mesh_frame = pd.DataFrame.from_dict(mesh_term_map, orient = 'index')\n",
    "mesh_frame.to_csv(f\"{DATA_STORAGE}/mesh_term_mappings.csv\")\n",
    "\n",
    "\n",
    "cleaned_trials['cleaned_sponsor'] = cleaned_trials['lead_sponsor'].apply(remove_punctuation)\n",
    "cleaned_trials['cln_start_date']= cleaned_trials['start_date'].apply(convert_date)\n",
    "cleaned_trials['cln_completion_date']= cleaned_trials['completion_date'].apply(convert_date)\n",
    "cleaned_trials['duration'] = cleaned_trials.apply(calculate_duration, axis = 1)\n",
    "cleaned_trials[\"matched_conditions\"] = cleaned_trials[\"conditions\"].apply(add_mesh_mappings, term_map=mesh_term_map)\n",
    "cleaned_trials['llm_annotations'] = [[] for _ in range(len(cleaned_trials))]\n",
    "cleaned_trials.shape\n",
    "\n",
    "#Trial saved as CSV for ease of review and as a pkl - the pkl should be used by the annotator notebook\n",
    "cleaned_trials.to_csv(f\"{DATA_STORAGE}/cleaned_trials.csv\")\n",
    "with open(f\"{DATA_STORAGE}/cleaned_trials.pkl\", 'wb') as f:\n",
    "    pickle.dump(cleaned_trials, f)\n",
    "logger.info(f\"Saved {cleaned_trials.shape[0]} trials after data cleaning in {DATA_STORAGE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f9a78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Uncomment to reload the Dataframe from pickle of Necessary\n",
    "#cleaned_trials_loc = \"data/cleaned_trials.pkl\"\n",
    "#if Path(cleaned_trials_loc).exists():\n",
    "#    with open(cleaned_trials_loc, \"rb\") as f:\n",
    "#        cleaned_trials = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glp-1-landscape-nG0L0imC-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
